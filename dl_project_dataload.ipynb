{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Meer Mustafa\n",
    "# March 31, 2018\n",
    "\n",
    "\n",
    "##### script that transforms csv's containing genomic signal features into 3D arrays (width x length x 1depth dimension per signal feature)\n",
    "\n",
    "# 1 CSV = 1 signal\n",
    "# each CSV is ordered by guides as rows and signal at genomic site as columns\n",
    "\n",
    "# goal:\n",
    "# is to produce from CSVs of signal vectors an output of np arrays \n",
    "# -- these arrays can be thought of as images - use the HW1 Question1.npz as an example\n",
    "# save the arrays using np.savez('file') per x entry\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. initialize a master array - a single array for each x input guide with shape (# of inputs, feature depth (# of signals), rows = 4 for a 4x repeated signal, columns = 200 for each bp signal)\n",
    "# 2. read in csv iteratively (each csv contains one signal type for all x input guides) containing signal data\n",
    "# 3. convert csv to np array\n",
    "# 4. store each csv's elements (rows are signal at 1 guide) as the 1st dimension in np.array(shape=i, _, _)\n",
    "\n",
    "# 5. after full input arrays is created and values are stored, \n",
    "# iterate through the first dimension (guides) of the full input array and save a single guide array in a new dir for inputs as np.savez('inputs/filename') named after the unique ID guide000001\n",
    "\n",
    "# 6. after single arrays are saved as single files, create the master CSV that will be used to track the 1. guide file name and the 2. label for that guide file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processingBatchENCODEdownload.R',\n",
       " 'createInputMatricesChipSeq_argsVersion.R',\n",
       " 'createInputMatricesChipSeq.R',\n",
       " 'Untitled.R',\n",
       " 'BAMReadsOverBEDIntervals.R',\n",
       " 'BAMReadsOverBEDIntervals_parallelBAMs.R']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through the contents of a directory\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# os.path gives both directories and files in path but want only files\n",
    "onlyfiles = [f for f in listdir() if isfile(join( f))]\n",
    "\n",
    "# with pattern match of files\n",
    "onlyfiles = [f for f in listdir() if f.endswith('.R')]\n",
    "\n",
    "# option 2 of pattern match\n",
    "onlyfiles = [f for f in listdir() if '.R' in f]\n",
    "onlyfiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    object\n",
      "dtype: object\n",
      "[[ '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3']\n",
      " [ '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4']\n",
      " [ '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4']\n",
      " ..., \n",
      " [ '1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']\n",
      " [ '1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']\n",
      " [ '1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']]\n",
      "112161\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# straight from csv to np array\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "\n",
    "# my_data = genfromtxt('../Data/CRISPRScreen/inputs/WDR5-human.A549.ENCFF851DKI.bam.MYC.bedgraph.200flanking_pileups.csv', delimiter=',')\n",
    "# my_data\n",
    "\n",
    "# option 2 for loading csv:\n",
    "df=pd.read_csv('../Data/CRISPRScreen/inputs/chipvectorbedgraphCSVs/WDR5-human.A549.ENCFF851DKI.bam.MYC.bedgraph.200flanking_pileups.csv', sep=',',header=None)\n",
    "print(df.dtypes)\n",
    "print(df.values)\n",
    "print(df.shape[0])\n",
    "\n",
    "### replace incorrect format of the csv with nparray csv\n",
    "# because the data is a literal string, we need to split based on whitespace\n",
    "# then we can iterate through this resulting list of strings and turn them into integers\n",
    "# index the df to pull out rows and columns\n",
    "# option 1 - works\n",
    "#[int(num) for num in df.iloc[0, ][0].split(' ')]\n",
    "# option 2 - works\n",
    "numlist = list(map(int, df.iloc[0,: ][0].split(' ')))\n",
    "#np.array([numlist])\n",
    "df.iloc[0,:][0] = np.array([numlist])\n",
    "print(np.array(df.iloc[1,:][0] ))\n",
    "type(df.iloc[1,:][0].split(' ') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112161, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "        2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## replace incorrect format of the csv with nparray csv\n",
    "for i in range(0,df.shape[0]):\n",
    "    # print(i)\n",
    "    \n",
    "    # save the ith row of the df back as a np array integer version of itself\n",
    "    numlist = [int(num) for num in df.iloc[i , : ][0].split(' ')]\n",
    "    \n",
    "    # save back\n",
    "    df.iloc[i, : ][0] = np.array([numlist])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.iloc[0,:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "1     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "2     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "3     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "4     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "5     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "6     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "7     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "8     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "9     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "10    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "11    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,...\n",
       "12    [[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3,...\n",
       "13    [[2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...\n",
       "14    [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...\n",
       "15    [[3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,...\n",
       "16    [[3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3,...\n",
       "17    [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 2,...\n",
       "18    [[3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,...\n",
       "19    [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:20,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterInputsArray =  np.zeros(shape = (df.shape[0], # # of feature maps\n",
    "                  42, # # of channels/feature depths e.g. RGB channels for images. this should be length of features (i.e. # of signal csv files)\n",
    "                  1, # # of x rows\n",
    "                  200) # # of y columns\n",
    "        )\n",
    "masterInputsArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112161, 42, 1, 200)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterInputsArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out filling in the master array\n",
    "masterInputsArray[0, # zeroth guide\n",
    "                  0, # ith feature layer\n",
    "                 :, # : results in repeated arrays, an index results in single occurence of array\n",
    "                 :] = df.iloc[0,][0] # all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  3.,  3.,  3.,  3.,  3.,\n",
       "         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "         3.,  3.,  3.,  3.,  3.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterInputsArray[0,\n",
    "                  0,\n",
    "                 :,\n",
    "                 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112161, 42, 1, 200)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterInputsArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,\n",
       " 32,\n",
       " ['RCOR1-human.A549.ENCFF215VRH.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CEBPB-human.A549.ENCFF000MWY.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CTCF-human.A549.ENCFF000VPA.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CHD1-human.A549.ENCFF019TJM.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'PHF8-human.A549.ENCFF156ZIB.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'KDM1A-human.A549.ENCFF843XEZ.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'MYC-human.A549.ENCFF518QII.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'MYC-human.A549.ENCFF000VOS.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'POLR2A-human.A549.ENCFF555WWS.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'POLR2A-human.A549.ENCFF000RME.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CHD7-human.A549.ENCFF324ZFJ.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CEBPB-human.A549.ENCFF940YYO.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'PBX3-human.A549.ENCFF000NEB.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CHD4-human.A549.ENCFF449GDV.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'EHMT2-human.A549.ENCFF730KGN.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CTCF-human.A549.ENCFF939MPS.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'TEAD4-human.A549.ENCFF000NHZ.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CBX8-human.A549.ENCFF789JGE.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'RAD21-human.A549.ENCFF000NFC.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'E2F6-human.A549.ENCFF000MYI.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CTCF-human.A549.ENCFF292MAD.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'HDAC2-human.A549.ENCFF484DFP.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'ESRRA-human.A549.ENCFF466OCY.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'ELK1-human.A549.ENCFF035OKO.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'WDR5-human.A549.ENCFF851DKI.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CBX2-human.A549.ENCFF573RUL.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'H3K4me3-human.A549.ENCFF001ELO.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'RAD21-human.A549.ENCFF931GZJ.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'NFE2L2-human.A549.ENCFF123GAA.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CTCF-human.A549.ENCFF000RLW.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'KDM5A-human.A549.ENCFF355VOF.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       "  'CEBPB-human.A549.ENCFF000VOJ.bam.MYC.bedgraph.200flanking_pileups.csv'])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,:][0].shape[1], len(csvfiles), csvfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112161, 15, 1, 200), (112161, 1))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterInputsArray =  np.zeros(shape = (df.shape[0], # # of feature maps\n",
    "                  len(csvfiles) , # # of channels/feature depths e.g. RGB channels for images. this should be length of features (i.e. # of signal csv files)\n",
    "                  1, # # of x rows\n",
    "                  df.iloc[0,:][0].shape[1] ) # pull the # of columns from the 1st csv signal file's columns i.e. # of y columns\n",
    "        )\n",
    "masterInputsArray.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterInputsArray =  np.zeros(shape = (df.shape[0], # # of inputs\n",
    "                  1 , # # of channels/feature depths e.g. RGB channels for images. this should be length of features (i.e. # of signal csv files)\n",
    "                  1, # # of x rows\n",
    "                  df.iloc[0,:][0].shape[1]) # pull the # of columns from the 1st csv signal file's columns i.e. # of y columns\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the master input is 112161\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-319bdd377bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m           \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# ith feature layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m          \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# : results in repeated arrays, an index results in single occurence of array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m          :] = df.iloc[inputsidx, : ]\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# 1-4. \n",
    "# store each csv's elements (rows are signal at 1 guide) as the 1st dimension in np.array(shape=i, _, _)\n",
    "\n",
    "# iterate through csvs\n",
    "filepattern = '.csv'\n",
    "filedir = '../Data/CRISPRScreen/inputs/'\n",
    "csvfiles = [f for f in listdir( filedir ) if f.endswith( filepattern )]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make the master np array to hold all inputs (later save as single nps)\n",
    "masterInputsArray =  np.zeros(shape = (df.shape[0], # # of feature maps\n",
    "                  1 , # # of channels/feature depths e.g. RGB channels for images. this should be length of features (i.e. # of signal csv files)\n",
    "                  1, # # of x rows\n",
    "                  df.iloc[0,:][0].shape[1]) # pull the # of columns from the 1st csv signal file's columns i.e. # of y columns\n",
    "        )\n",
    "print('The shape of the master input is %s' %masterInputsArray.shape[0] )\n",
    "\n",
    "\n",
    "\n",
    "# for featuresidx in range(0, masterInputsArray.shape[1]):\n",
    "#     #print('Now working on loading in, correcting format to np array and saving to master input array:' %csvfiles[featuresidx])\n",
    "    \n",
    "#     # read in csv as pd df\n",
    "#     #df = pd.read_csv('../Data/CRISPRScreen/inputs/chipvectorbedgraphCSVs/%s' %csvfiles[featuresidx], sep=',', header=None)\n",
    "#     df = pd.read_csv('../Data/CRISPRScreen/inputs/chipvectorbedgraphCSVs/POLR2A-human.A549.ENCFF000RME.bam.MYC.bedgraph.200flanking_pileups.csv' , sep=',', header=None)\n",
    "    \n",
    "#     # convert df into integer np array\n",
    "#     ## replace incorrect format of the csv with nparray csv\n",
    "#     for i in range(0,df.shape[0]):\n",
    "#         # print(i)\n",
    "\n",
    "#         # save the ith row of the df back as a np array integer version of itself\n",
    "#         numlist = [int(num) for num in df.iloc[i , : ][0].split(' ')]\n",
    "\n",
    "#         # save back to original df\n",
    "#         df.iloc[i, : ][0] = np.array([numlist])\n",
    "        \n",
    "        \n",
    "\n",
    "#     # now data is in the correct format, need to save into a np array\n",
    "#     # already are iterating through the feature depths (2nd dim), now\n",
    "#     # iterate through the guides (1st dim)\n",
    "#     for inputsidx in range(0, masterInputsArray.shape[0]):\n",
    "#         masterInputsArray[inputsidx, # ith guide\n",
    "#               featuresidx, # ith feature layer\n",
    "#              :, # : results in repeated arrays, an index results in single occurence of array\n",
    "#              :] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####  all inputs, 1 feature test example\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for featuresidx in range(0, masterInputsArray.shape[1]):\n",
    "#print('Now working on loading in, correcting format to np array and saving to master input array:' %csvfiles[featuresidx])\n",
    "\n",
    "# read in csv as pd df\n",
    "#df = pd.read_csv('../Data/CRISPRScreen/inputs/chipvectorbedgraphCSVs/%s' %csvfiles[featuresidx], sep=',', header=None)\n",
    "df = pd.read_csv('../Data/CRISPRScreen/inputs/chipvectorbedgraphCSVs/POLR2A-human.A549.ENCFF000RME.bam.MYC.bedgraph.200flanking_pileups.csv' , sep=',', header=None)\n",
    "\n",
    "# convert df into integer np array\n",
    "## replace incorrect format of the csv with nparray csv\n",
    "for i in range(0,df.shape[0]):\n",
    "    # print(i)\n",
    "\n",
    "    # save the ith row of the df back as a np array integer version of itself\n",
    "    numlist = [int(num) for num in df.iloc[i , : ][0].split(' ')]\n",
    "\n",
    "    # save back to original df\n",
    "    df.iloc[i, : ][0] = np.array([numlist])\n",
    "\n",
    "\n",
    "\n",
    "# now data is in the correct format, need to save into a np array\n",
    "# already are iterating through the feature depths (2nd dim), now\n",
    "# iterate through the guides (1st dim)\n",
    "for inputsidx in range(0, masterInputsArray.shape[0]):\n",
    "    masterInputsArray[inputsidx, # ith guide\n",
    "          0, # ith feature layer\n",
    "         :, # : results in repeated arrays, an index results in single occurence of array\n",
    "         :] = df.iloc[inputsidx, : ]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, (112161, 1), 0    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,...\n",
       " Name: 0, dtype: object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterInputsArray.sum(), df.shape,  df.iloc[0,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-9e2a8fee3520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# TO TROUBLESHOOT SAVE THE ITH INPUT AND ONLY 1 FEATURE TYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m#np.save(filePathAndNameToSaveTo, df[i,:] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiledirToSaveTo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mguideIDNames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguideIDNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_chip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 raise ValueError(\"Location based indexing can only have [%s] \"\n\u001b[1;32m    191\u001b[0m                                  \"types\" % self._valid_types)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1595\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1597\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1598\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1599\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1636\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "df\n",
    "\n",
    "filedirToSaveTo = '../Data/CRISPRScreen/inputs/chip_npz/'\n",
    "filedirToPullFrom = '/Data/CRISPRScreen/inputs/chip_npz/'\n",
    "featureName = '.ChIP'\n",
    "\n",
    "filePathAndNameListToSaveTo = list()\n",
    "filePathAndNameListToPullFrom = list()\n",
    "filePathAndNameListToSaveToDNA = list()\n",
    "\n",
    "# create unique IDs for guides\n",
    "guideIDNames = list()\n",
    "for i in range(1, df.shape[0]+1): # ranges from 1 to the max number of inputs\n",
    "    #print(i)\n",
    "    guideIDNames.append( 'MYCScreen_%06d' %i) # pad zeroes and use string substitution\n",
    "    \n",
    "    # save the np array using np.savez, automatically gives the array, that is saved inside the npz, the name 'arr_0'\n",
    "    \n",
    "    # first create the name the file will be named after\n",
    "    # automatically has .npz extension name\n",
    "    filePathAndNameToSaveTo = str( guideIDNames[len(guideIDNames)-1] + '_chip' + '.npy')\n",
    "    filePathAndNameListToSaveTo.append(filePathAndNameToSaveTo)\n",
    "    \n",
    "    filePathAndNameToSaveToDNA = str( guideIDNames[len(guideIDNames)-1] + '_DNA' + '.npy')\n",
    "    filePathAndNameListToSaveToDNA.append(filePathAndNameToSaveToDNA)\n",
    "    \n",
    "    #str(filedirToSaveTo + guideIDNames[len(guideIDNames)-1] + featureName)\n",
    "    \n",
    "    \n",
    "    # create separate name to pull from\n",
    "    filePathAndNameToPullFrom = str(filedirToPullFrom + guideIDNames[len(guideIDNames)-1] + '_chip' + featureName)\n",
    "    # create list of file path&names\n",
    "    filePathAndNameList.append(filePathAndNameToPullFrom)\n",
    "    \n",
    "    # save the ith input, including all features\n",
    "    # TO TROUBLESHOOT SAVE THE ITH INPUT AND ONLY 1 FEATURE TYPE\n",
    "    #np.save(filePathAndNameToSaveTo, df[i,:] )\n",
    "    np.savez(str(filedirToSaveTo + guideIDNames[len(guideIDNames)-1] + '_chip'), x = df.iloc[i,:][0] )\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# check the names\n",
    "guideIDNames[0:3],guideIDNames[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['MYCScreen_000001', 'MYCScreen_000002', 'MYCScreen_000003'],\n",
       " ['MYCScreen_112157',\n",
       "  'MYCScreen_112158',\n",
       "  'MYCScreen_112159',\n",
       "  'MYCScreen_112160',\n",
       "  'MYCScreen_112161'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that creating the master np array is done, let's segment the full array into singlular inputs. \n",
    "# this will make it much easier later on because of memory usage from loading in large amounts of data\n",
    "\n",
    "filedirToSaveTo = '../Data/CRISPRScreen/inputs/chip_npz/'\n",
    "filedirToPullFrom = '/Data/CRISPRScreen/inputs/chip_npz/'\n",
    "featureName = '.ChIP'\n",
    "\n",
    "filePathAndNameListToSaveTo = list()\n",
    "filePathAndNameListToPullFrom = list()\n",
    "filePathAndNameListToSaveToDNA = list()\n",
    "\n",
    "# create unique IDs for guides\n",
    "guideIDNames = list()\n",
    "for i in range(1, masterInputsArray.shape[0]+1): # ranges from 1 to the max number of inputs\n",
    "    #print(i)\n",
    "    guideIDNames.append( 'MYCScreen_%06d' %i) # pad zeroes and use string substitution\n",
    "    \n",
    "    # save the np array using np.savez, automatically gives the array, that is saved inside the npz, the name 'arr_0'\n",
    "    \n",
    "    # first create the name the file will be named after\n",
    "    # automatically has .npz extension name\n",
    "    filePathAndNameToSaveTo = str( guideIDNames[len(guideIDNames)-1] + '_chip' + '.npy')\n",
    "    filePathAndNameListToSaveTo.append(filePathAndNameToSaveTo)\n",
    "    \n",
    "    filePathAndNameToSaveToDNA = str( guideIDNames[len(guideIDNames)-1] + '_DNA' + '.npy')\n",
    "    filePathAndNameListToSaveToDNA.append(filePathAndNameToSaveToDNA)\n",
    "    \n",
    "    #str(filedirToSaveTo + guideIDNames[len(guideIDNames)-1] + featureName)\n",
    "    \n",
    "    \n",
    "    # create separate name to pull from\n",
    "    filePathAndNameToPullFrom = str(filedirToPullFrom + guideIDNames[len(guideIDNames)-1] + '_chip' + featureName)\n",
    "    # create list of file path&names\n",
    "    filePathAndNameList.append(filePathAndNameToPullFrom)\n",
    "    \n",
    "    # save the ith input, including all features\n",
    "    # TO TROUBLESHOOT SAVE THE ITH INPUT AND ONLY 1 FEATURE TYPE\n",
    "    #np.save(filePathAndNameToSaveTo, masterInputsArray[i,:,:,:] )\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# check the names\n",
    "guideIDNames[0:3],guideIDNames[-5:]\n",
    "\n",
    "# now have a list of names to name individual file names after (1 file per input)\n",
    "# iterate through the inputs in the master array, subset the master, and save in npz file\n",
    "\n",
    "# for np.savez:\n",
    "# If arguments are passed in with no keywords, the corresponding variable names, in the .npz file, are ‘arr_0’, ‘arr_1’, etc. \n",
    "# If keyword arguments are given, the corresponding variable names, in the .npz file will match the keyword names.\n",
    "\n",
    "# e.g.:\n",
    "# npzfile = np.load('Question1.npz') # 'Question1.npz' is provided under /beegfs/ga4493/data/HW2 folder at HPC\n",
    "# print(npzfile.files) # check the variable names\n",
    "# x = npzfile['x']\n",
    "# w = npzfile['w']\n",
    "# b = npzfile['b']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MYCScreen_000001_chip.npy', array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]]), (42, 1, 200))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePathAndNameListToSaveTo[0], masterInputsArray[1,:,:,:], masterInputsArray[1,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(filePathAndNameListToSaveTo[0], masterInputsArray[1,:,:,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load(filePathAndNameListToSaveTo[0]+'.npz')\n",
    "a.files\n",
    "a['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csvfiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1d6512590638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcsvfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'csvfiles' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.]]), 'y': array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.]])}\n",
      "['x', 'y']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={ 'x':masterInputsArray[1,1,:,:] , 'y':masterInputsArray[1,2,:,:]}\n",
    "print(d)\n",
    "\n",
    "\n",
    "np.savez('test', **d )\n",
    "\n",
    "# loading in the npz singular files - put this code inside the dataloader class object\n",
    "npzfile = np.load('test.npz')\n",
    "\n",
    "print(npzfile.files)\n",
    "testarray = npzfile['x']\n",
    "testarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RCOR1-human.A549.ENCFF215VRH.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CEBPB-human.A549.ENCFF000MWY.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CTCF-human.A549.ENCFF000VPA.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CHD1-human.A549.ENCFF019TJM.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'PHF8-human.A549.ENCFF156ZIB.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'KDM1A-human.A549.ENCFF843XEZ.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'MYC-human.A549.ENCFF518QII.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'MYC-human.A549.ENCFF000VOS.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'POLR2A-human.A549.ENCFF555WWS.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'POLR2A-human.A549.ENCFF000RME.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CHD7-human.A549.ENCFF324ZFJ.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CEBPB-human.A549.ENCFF940YYO.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'PBX3-human.A549.ENCFF000NEB.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CHD4-human.A549.ENCFF449GDV.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'EHMT2-human.A549.ENCFF730KGN.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CTCF-human.A549.ENCFF939MPS.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'TEAD4-human.A549.ENCFF000NHZ.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CBX8-human.A549.ENCFF789JGE.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'RAD21-human.A549.ENCFF000NFC.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'E2F6-human.A549.ENCFF000MYI.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CTCF-human.A549.ENCFF292MAD.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'HDAC2-human.A549.ENCFF484DFP.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'ESRRA-human.A549.ENCFF466OCY.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'ELK1-human.A549.ENCFF035OKO.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'WDR5-human.A549.ENCFF851DKI.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CBX2-human.A549.ENCFF573RUL.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'H3K4me3-human.A549.ENCFF001ELO.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'RAD21-human.A549.ENCFF931GZJ.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'NFE2L2-human.A549.ENCFF123GAA.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CTCF-human.A549.ENCFF000RLW.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'KDM5A-human.A549.ENCFF355VOF.bam.MYC.bedgraph.200flanking_pileups.csv',\n",
       " 'CEBPB-human.A549.ENCFF000VOJ.bam.MYC.bedgraph.200flanking_pileups.csv']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through csvs\n",
    "filepattern = '.csv'\n",
    "filedir = '../Data/CRISPRScreen/inputs/chipvectorbedgraphCSVs/'\n",
    "csvfiles = [f for f in listdir( filedir ) if f.endswith( filepattern )]\n",
    "csvfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filePathAndNameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filedir = '../Data/CRISPRScreen/inputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/CRISPRScreen/inputs/MYCScreen_000001.ChIP'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePathAndName = str(filedir + guideIDNames[0] + featureName)\n",
    "filePathAndName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(filename, masterInputsArray[0,:,:,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in the npz singular files - put this code inside the dataloader class object\n",
    "npzfile = np.load('MYCScreen_000001.ChIP.npz')\n",
    "print(npzfile.files)\n",
    "testarray = npzfile['arr_0']\n",
    "testarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UniqueID', 'chr', 'sgRNA_start', 'sgRNA_end', 'strand',\n",
      "       'sgRNA_sequence', 'Set', 'Gene', 'bc1', 'bc2', 'bc3', 'bc4', 'bc5',\n",
      "       'bc6', 'bc7', 'bc8', 'MYCLibrary01', 'finalToInitial', 'bc1VSbc1',\n",
      "       'bc2VSbc1', 'bc3VSbc1', 'bc4VSbc1', 'bc5VSbc1', 'bc6VSbc1', 'bc7VSbc1',\n",
      "       'bc8VSbc1', 'functionalLabeltop1percentNT'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meer/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               CS             ChIPFileSource             DNAFileSource  \\\n",
       "0      -0.083997  MYCScreen_000001_chip.npy  MYCScreen_000001_DNA.npy   \n",
       "1       0.916003  MYCScreen_000002_chip.npy  MYCScreen_000002_DNA.npy   \n",
       "2      -0.557929  MYCScreen_000003_chip.npy  MYCScreen_000003_DNA.npy   \n",
       "3      -1.907120  MYCScreen_000004_chip.npy  MYCScreen_000004_DNA.npy   \n",
       "4       0.746078  MYCScreen_000005_chip.npy  MYCScreen_000005_DNA.npy   \n",
       "5       0.303026  MYCScreen_000006_chip.npy  MYCScreen_000006_DNA.npy   \n",
       "6      -0.668960  MYCScreen_000007_chip.npy  MYCScreen_000007_DNA.npy   \n",
       "7       0.205509  MYCScreen_000008_chip.npy  MYCScreen_000008_DNA.npy   \n",
       "8      -0.244462  MYCScreen_000009_chip.npy  MYCScreen_000009_DNA.npy   \n",
       "9      -1.083997  MYCScreen_000010_chip.npy  MYCScreen_000010_DNA.npy   \n",
       "10     -0.614512  MYCScreen_000011_chip.npy  MYCScreen_000011_DNA.npy   \n",
       "11      0.626496  MYCScreen_000012_chip.npy  MYCScreen_000012_DNA.npy   \n",
       "12      1.003465  MYCScreen_000013_chip.npy  MYCScreen_000013_DNA.npy   \n",
       "13      0.237931  MYCScreen_000014_chip.npy  MYCScreen_000014_DNA.npy   \n",
       "14      0.681537  MYCScreen_000015_chip.npy  MYCScreen_000015_DNA.npy   \n",
       "15     -0.882364  MYCScreen_000016_chip.npy  MYCScreen_000016_DNA.npy   \n",
       "16      0.800525  MYCScreen_000017_chip.npy  MYCScreen_000017_DNA.npy   \n",
       "17     -0.264570  MYCScreen_000018_chip.npy  MYCScreen_000018_DNA.npy   \n",
       "18      0.359609  MYCScreen_000019_chip.npy  MYCScreen_000019_DNA.npy   \n",
       "19     -0.668960  MYCScreen_000020_chip.npy  MYCScreen_000020_DNA.npy   \n",
       "20     -0.949068  MYCScreen_000021_chip.npy  MYCScreen_000021_DNA.npy   \n",
       "21      1.179037  MYCScreen_000022_chip.npy  MYCScreen_000022_DNA.npy   \n",
       "22     -0.762069  MYCScreen_000023_chip.npy  MYCScreen_000023_DNA.npy   \n",
       "23     -0.614512  MYCScreen_000024_chip.npy  MYCScreen_000024_DNA.npy   \n",
       "24      0.122453  MYCScreen_000025_chip.npy  MYCScreen_000025_DNA.npy   \n",
       "25      0.157011  MYCScreen_000026_chip.npy  MYCScreen_000026_DNA.npy   \n",
       "26     -0.005995  MYCScreen_000027_chip.npy  MYCScreen_000027_DNA.npy   \n",
       "27     -0.520097  MYCScreen_000028_chip.npy  MYCScreen_000028_DNA.npy   \n",
       "28     -0.581497  MYCScreen_000029_chip.npy  MYCScreen_000029_DNA.npy   \n",
       "29      1.266500  MYCScreen_000030_chip.npy  MYCScreen_000030_DNA.npy   \n",
       "...          ...                        ...                       ...   \n",
       "112131  0.272146  MYCScreen_112132_chip.npy  MYCScreen_112132_DNA.npy   \n",
       "112132  0.500965  MYCScreen_112133_chip.npy  MYCScreen_112133_DNA.npy   \n",
       "112133  0.500965  MYCScreen_112134_chip.npy  MYCScreen_112134_DNA.npy   \n",
       "112134  0.693610  MYCScreen_112135_chip.npy  MYCScreen_112135_DNA.npy   \n",
       "112135 -0.419600  MYCScreen_112136_chip.npy  MYCScreen_112136_DNA.npy   \n",
       "112136  0.205509  MYCScreen_112137_chip.npy  MYCScreen_112137_DNA.npy   \n",
       "112137 -0.352486  MYCScreen_112138_chip.npy  MYCScreen_112138_DNA.npy   \n",
       "112138  0.568079  MYCScreen_112139_chip.npy  MYCScreen_112139_DNA.npy   \n",
       "112139  0.006200  MYCScreen_112140_chip.npy  MYCScreen_112140_DNA.npy   \n",
       "112140  0.003465  MYCScreen_112141_chip.npy  MYCScreen_112141_DNA.npy   \n",
       "112141 -0.557929  MYCScreen_112142_chip.npy  MYCScreen_112142_DNA.npy   \n",
       "112142 -0.586498  MYCScreen_112143_chip.npy  MYCScreen_112143_DNA.npy   \n",
       "112143 -0.142891  MYCScreen_112144_chip.npy  MYCScreen_112144_DNA.npy   \n",
       "112144 -0.684390  MYCScreen_112145_chip.npy  MYCScreen_112145_DNA.npy   \n",
       "112145 -0.856587  MYCScreen_112146_chip.npy  MYCScreen_112146_DNA.npy   \n",
       "112146  0.616442  MYCScreen_112147_chip.npy  MYCScreen_112147_DNA.npy   \n",
       "112147 -0.405926  MYCScreen_112148_chip.npy  MYCScreen_112148_DNA.npy   \n",
       "112148 -0.285631  MYCScreen_112149_chip.npy  MYCScreen_112149_DNA.npy   \n",
       "112149  0.833540  MYCScreen_112150_chip.npy  MYCScreen_112150_DNA.npy   \n",
       "112150  0.674994  MYCScreen_112151_chip.npy  MYCScreen_112151_DNA.npy   \n",
       "112151 -0.415203  MYCScreen_112152_chip.npy  MYCScreen_112152_DNA.npy   \n",
       "112152 -0.471021  MYCScreen_112153_chip.npy  MYCScreen_112153_DNA.npy   \n",
       "112153  0.375434  MYCScreen_112154_chip.npy  MYCScreen_112154_DNA.npy   \n",
       "112154 -0.920499  MYCScreen_112155_chip.npy  MYCScreen_112155_DNA.npy   \n",
       "112155  0.131015  MYCScreen_112156_chip.npy  MYCScreen_112156_DNA.npy   \n",
       "112156  2.003465  MYCScreen_112157_chip.npy  MYCScreen_112157_DNA.npy   \n",
       "112157  0.050304  MYCScreen_112158_chip.npy  MYCScreen_112158_DNA.npy   \n",
       "112158 -0.868269  MYCScreen_112159_chip.npy  MYCScreen_112159_DNA.npy   \n",
       "112159  0.739125  MYCScreen_112160_chip.npy  MYCScreen_112160_DNA.npy   \n",
       "112160  0.145484  MYCScreen_112161_chip.npy  MYCScreen_112161_DNA.npy   \n",
       "\n",
       "           InputUniqueID  label  \n",
       "0       MYCScreen_000001      0  \n",
       "1       MYCScreen_000002      0  \n",
       "2       MYCScreen_000003      0  \n",
       "3       MYCScreen_000004      1  \n",
       "4       MYCScreen_000005      0  \n",
       "5       MYCScreen_000006      0  \n",
       "6       MYCScreen_000007      0  \n",
       "7       MYCScreen_000008      0  \n",
       "8       MYCScreen_000009      0  \n",
       "9       MYCScreen_000010      0  \n",
       "10      MYCScreen_000011      0  \n",
       "11      MYCScreen_000012      0  \n",
       "12      MYCScreen_000013      0  \n",
       "13      MYCScreen_000014      0  \n",
       "14      MYCScreen_000015      0  \n",
       "15      MYCScreen_000016      0  \n",
       "16      MYCScreen_000017      0  \n",
       "17      MYCScreen_000018      0  \n",
       "18      MYCScreen_000019      0  \n",
       "19      MYCScreen_000020      0  \n",
       "20      MYCScreen_000021      0  \n",
       "21      MYCScreen_000022      0  \n",
       "22      MYCScreen_000023      0  \n",
       "23      MYCScreen_000024      0  \n",
       "24      MYCScreen_000025      0  \n",
       "25      MYCScreen_000026      0  \n",
       "26      MYCScreen_000027      0  \n",
       "27      MYCScreen_000028      0  \n",
       "28      MYCScreen_000029      0  \n",
       "29      MYCScreen_000030      0  \n",
       "...                  ...    ...  \n",
       "112131  MYCScreen_112132      0  \n",
       "112132  MYCScreen_112133      0  \n",
       "112133  MYCScreen_112134      0  \n",
       "112134  MYCScreen_112135      0  \n",
       "112135  MYCScreen_112136      0  \n",
       "112136  MYCScreen_112137      0  \n",
       "112137  MYCScreen_112138      0  \n",
       "112138  MYCScreen_112139      0  \n",
       "112139  MYCScreen_112140      0  \n",
       "112140  MYCScreen_112141      0  \n",
       "112141  MYCScreen_112142      0  \n",
       "112142  MYCScreen_112143      0  \n",
       "112143  MYCScreen_112144      0  \n",
       "112144  MYCScreen_112145      0  \n",
       "112145  MYCScreen_112146      0  \n",
       "112146  MYCScreen_112147      0  \n",
       "112147  MYCScreen_112148      0  \n",
       "112148  MYCScreen_112149      0  \n",
       "112149  MYCScreen_112150      0  \n",
       "112150  MYCScreen_112151      0  \n",
       "112151  MYCScreen_112152      0  \n",
       "112152  MYCScreen_112153      0  \n",
       "112153  MYCScreen_112154      0  \n",
       "112154  MYCScreen_112155      0  \n",
       "112155  MYCScreen_112156      0  \n",
       "112156  MYCScreen_112157      1  \n",
       "112157  MYCScreen_112158      0  \n",
       "112158  MYCScreen_112159      0  \n",
       "112159  MYCScreen_112160      0  \n",
       "112160  MYCScreen_112161      0  \n",
       "\n",
       "[112161 rows x 5 columns]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### master CSV creation\n",
    "lib = pd.read_csv('../Data/CRISPRScreen/A549Rep1MYCScreen_OverreppedGuideRemoved_NormalizedReadCounts_FunctionalLabelAgainstTop1PercentNT2018-03-31.csv')\n",
    "print(lib.columns)\n",
    "#lib.loc[:,['functionalLabeltop1percentNT']].tolist()\n",
    "labelslist = lib['functionalLabeltop1percentNT'].tolist()\n",
    "cslist = lib['bc8VSbc1'].tolist()\n",
    "len(labelslist)\n",
    "subsetlabelslist,subsetCSlist = labelslist[0 : masterInputsArray.shape[0]], cslist[0 : masterInputsArray.shape[0]]\n",
    "\n",
    "\n",
    "d = {'InputUniqueID' : guideIDNames, \n",
    "     'label' : subsetlabelslist,\n",
    "     'CS' : subsetCSlist,\n",
    "      'ChIPFileSource' : filePathAndNameListToSaveTo,\n",
    "     'DNAFileSource' : filePathAndNameListToSaveToDNA\n",
    "    }\n",
    "masterCSV = pd.DataFrame(data=d)\n",
    "masterCSV.head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write out csv\n",
    "masterCSV.to_csv(\"../Data/CRISPRScreen/masterDataLoadingCSV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112161"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subsetCSlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write out csv\n",
    "df.to_csv(\"\"C:/Folder/UpdatedData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112161"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.random.randint(low = 0, high = 1, size = masterInputsArray.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(low = 0, high = 1, size = masterInputsArray.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 30507), indices imply (1, 112161)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4296\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4297\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   2794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2795\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3005\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3006\u001b[0;31m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   4279\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 4280\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   4281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1, 30507), indices imply (1, 112161)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-292-3d036aedab19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilePathAndNameCSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguideIDNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasterInputsArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'InputUniqueID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfilePathAndNameCSV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 330\u001b[0;31m                                              copy=copy)\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4301\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4303\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   4278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4279\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 4280\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   4281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1, 30507), indices imply (1, 112161)"
     ]
    }
   ],
   "source": [
    "filePathAndNameCSV = pd.DataFrame(data = guideIDNames, index = np.arange(masterInputsArray.shape[0]) , columns=['InputUniqueID'])\n",
    "filePathAndNameCSV.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write out csv\n",
    "df.to_csv(\"\"C:/Folder/UpdatedData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c9185049d0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating an np array with 3 dimensions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#x_zeropad = np.zeros([x.shape[0],x.shape[1]+2,x.shape[2]+2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#x_zeropad[:,1:-1,1:-1] = x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "# creating an np array with 3 dimensions:\n",
    "x = np.array([1,2,3])\n",
    "#x_zeropad = np.zeros([x.shape[0],x.shape[1]+2,x.shape[2]+2])\n",
    "#x_zeropad[:,1:-1,1:-1] = x\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### create a class specific for our data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from skimage import color\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"Chest X-ray dataset from https://nihcc.app.box.com/v/ChestXray-NIHCC.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data_frame.iloc[idx, 0])\n",
    "        \n",
    "        #some cases io.imread brings more channels than 1 due to bitsize issues\n",
    "        image = io.imread(img_name,as_grey=True)\n",
    "        #or we can use the following\n",
    "        #if len(image.shape) > 2 and image.shape[2] == 4:\n",
    "        #    image = image[:,:,0]\n",
    "        \n",
    "        # data transfrom to zero mean unit variance\n",
    "        image = (image - image.mean()) / image.std()\n",
    "            \n",
    "        image_class = self.data_frame.iloc[idx, -1]\n",
    "        #print(img_name,image.shape)\n",
    "\n",
    "        sample = {'x': image[None,:], 'y': image_class}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### creating data loader objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable \n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "## data loaders\n",
    "chestXray_TrainData = ChestXrayDataset(csv_file='HW2_RandomTrainSet.csv',\n",
    "                                    root_dir='images')\n",
    "train_loader = DataLoader(chestXray_TrainData, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "chestXray_ValidationData = ChestXrayDataset(csv_file='HW2_RandomValidationSet.csv',\n",
    "                                    root_dir='images')\n",
    "validation_loader = DataLoader(chestXray_ValidationData, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "dataset_sizes = {'train': len(chestXray_TrainData), 'val': len(chestXray_ValidationData)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
